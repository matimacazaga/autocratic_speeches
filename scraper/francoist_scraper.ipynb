{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import unidecode\n",
    "import os\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(os.getcwd()) # initial working directory\n",
    "output_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.generalisimofranco.com/Discursos/discursos/00000.HTM\"\n",
    "url_base = \"http://www.generalisimofranco.com/Discursos/discursos/\"\n",
    "\n",
    "source = requests.get(url).text\n",
    "soup = BeautifulSoup(source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all years in which Franco gave speeches (each year is itself a link)\n",
    "all_years = soup.find_all('a', href = re.compile(\"0000\"))\n",
    "all_years = [i for i in all_years if i.string is not None]\n",
    "all_years = [i for i in all_years if \"Discursos\" in i.string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of (year, link) entries for each year\n",
    "year_list = []\n",
    "for one_year in all_years:\n",
    "    \n",
    "    year_string = one_year.string.replace(\".\", \"\")[-4:] # extract year\n",
    "    year = int(year_string) # convert year from string to int\n",
    "    \n",
    "    extension = one_year['href']\n",
    "    year_link = url_base + str(extension)\n",
    "    \n",
    "    year_list.append([year, year_link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each year, get the links to each of the speeches\n",
    "all_speeches = []\n",
    "for i in year_list:\n",
    "\n",
    "    year = i[0]\n",
    "    yearly_url = i[1]\n",
    "    yearly_source = requests.get(yearly_url).text\n",
    "    yearly_soup = BeautifulSoup(yearly_source, 'html.parser')\n",
    "    all_yearly_speeches = yearly_soup.find_all('a', href = re.compile('.*({}).*'.format(year))) # all 'a' tags containing key word 'year' in the corresponding href\n",
    "\n",
    "    yearly_speeches = [] # list to be filled with links to all speeches of a single year\n",
    "    count = 0\n",
    "    for speech in all_yearly_speeches:\n",
    "        \n",
    "        extension = speech['href']\n",
    "        speech_link = url_base + str(extension)\n",
    "\n",
    "        yearly_speeches.append([year, speech_link, count])\n",
    "        count += 1\n",
    "    \n",
    "    all_speeches.append(yearly_speeches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten list\n",
    "all_speeches = [speech for yearly_speeches in all_speeches for speech in yearly_speeches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each speech, concatenate all (sub-)headings and paragraphs into a single text string\n",
    "for speech in all_speeches:\n",
    "    speech_url = speech[1]\n",
    "    speech_source = requests.get(speech_url).text\n",
    "    speech_soup = BeautifulSoup(speech_source, 'html.parser')\n",
    "\n",
    "    all_paragraphs = speech_soup.find('blockquote').find_all(['p', 'span'])\n",
    "\n",
    "    text = str()\n",
    "    for paragraph in all_paragraphs:\n",
    "        content = paragraph.text.replace('\\r', '').replace('\\n', '')\n",
    "        text += ' ' + content\n",
    "\n",
    "    speech.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_speeches, columns=['Year', 'Link', 'Count', 'Text']) # convert to df\n",
    "df['Name'] = 'Francisco Franco' # add name column\n",
    "df['id'] = df['Year'].map(str) + '_' + df['Name'] + '_' + df['Count'].map(str)  \n",
    "df.drop(['Link', 'Count'], axis = 1) # drop link and count\n",
    "df = df[['Year', 'Name', 'id', 'Text']] # reorder columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save combined df\n",
    "with open(output_path + 'df.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
